{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas Data Types\n",
    "\n",
    "Pandas provides a variety of data types to store and manipulate different kinds of data efficiently. These data types are built on top of NumPy’s array types, which give Pandas its performance.\n",
    "\n",
    "Here are the key data types you’ll encounter in Pandas:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Object (String) Data Type**: \n",
    "This is the default data type for string data in Pandas. It can store any Python object, but it is typically used for text (string) data.\n",
    "\n",
    "- **Example**: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = {'Name': ['Alice', 'Bob', 'Charlie']}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  Here, the column `Name` contains string values, so Pandas assigns the `object` type.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Integer Data Type (`int64`)**:\n",
    "This data type is used to represent integer numbers (whole numbers). Pandas uses the `int64` type by default, which means it uses 64 bits to store integers.\n",
    "\n",
    "- **Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Age': [25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Here, the `Age` column contains integers, so it’s of type `int64`.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Floating Point Data Type (`float64`)**:\n",
    "This data type is used to represent decimal numbers or real numbers. Just like integers, Pandas uses the `float64` type by default, which stores 64-bit floating point numbers.\n",
    "\n",
    "- **Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Height': [5.5, 6.2, 5.8]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  The `Height` column contains floating point numbers, so it is of type `float64`.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Boolean Data Type (`bool`)**:\n",
    "Pandas uses the `bool` data type to store boolean values, which can be either `True` or `False`.\n",
    "\n",
    "- **Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Is_Adult': [True, False, True]}\n",
    "df = pd.DataFrame(data)\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  The `Is_Adult` column contains boolean values, so it’s of type `bool`.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Datetime Data Type (`datetime64`)**:\n",
    "Datetime data type is used to represent time and date values. It is very important when working with time series data.\n",
    "\n",
    "- **Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Date': ['2024-01-01', '2024-02-01', '2024-03-01']}\n",
    "df = pd.DataFrame(data)\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "  Here, `Date` has been converted to the `datetime64` data type.\n",
    "\n",
    "---\n",
    "\n",
    "### 6. **Categorical Data Type**:\n",
    "This is a special data type used to store categorical values, i.e., values that belong to a fixed set of categories. It is more memory efficient than using object types for categorical data.\n",
    "\n",
    "- **Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Category': ['A', 'B', 'A', 'C', 'B']}\n",
    "df = pd.DataFrame(data)\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  The `Category` column is now of type `category`.\n",
    "\n",
    "---\n",
    "\n",
    "### 7. **Timedelta Data Type (`timedelta64`)**:\n",
    "This data type is used to represent differences in dates and times, i.e., time durations.\n",
    "\n",
    "- **Example**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Time_Duration': ['1 days', '2 days', '3 days']}\n",
    "df = pd.DataFrame(data)\n",
    "df['Time_Duration'] = pd.to_timedelta(df['Time_Duration'])\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "### Summary of Pandas Data Types:\n",
    "| Data Type   | Description                                        | Example              |\n",
    "|-------------|----------------------------------------------------|----------------------|\n",
    "| `object`    | Typically used for text (string) data              | `\"Hello\"`            |\n",
    "| `int64`     | Integer values (whole numbers)                     | `5`, `100`           |\n",
    "| `float64`   | Floating-point numbers (decimal values)            | `3.14`, `2.71`       |\n",
    "| `bool`      | Boolean values (`True` or `False`)                 | `True`, `False`      |\n",
    "| `datetime64`| Date and time values                               | `2024-12-25`         |\n",
    "| `category`  | Categorical data (fixed set of categories)         | `'A'`, `'B'`         |\n",
    "| `timedelta` | Time differences (duration between dates/times)   | `1 days`, `2 hours`  |\n",
    "\n",
    "---\n",
    "\n",
    "### Converting Data Types in Pandas\n",
    "Pandas allows you to convert between data types using methods like:\n",
    "- `.astype()`: Convert a column to a specific type.\n",
    "- `pd.to_datetime()`: Convert to datetime.\n",
    "- `pd.to_timedelta()`: Convert to timedelta.\n",
    "- `pd.to_numeric()`: Convert to numeric data types.\n",
    "\n",
    "For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Age': [25, 30, 35]}\n",
    "df = pd.DataFrame(data)\n",
    "df['Age'] = df['Age'].astype('float64')  # Convert to float\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practice all with example\n",
    "\n",
    "### Create a DataFrame with Different Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Sample data with different types\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva'],\n",
    "    'Age': [25, 30, 35, 40, 22],  # Integer type\n",
    "    'Height': [5.5, 6.2, 5.8, 5.9, 5.6],  # Float type\n",
    "    'Is_Adult': [True, True, True, True, False],  # Boolean type\n",
    "    'Birthdate': ['1999-01-01', '1994-05-12', '1989-07-08', '1984-09-15', '2002-03-30']  # Date type\n",
    "}\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Convert Birthdate to datetime type\n",
    "df['Birthdate'] = pd.to_datetime(df['Birthdate'])\n",
    "\n",
    "# Display DataFrame and check data types\n",
    "print(\"DataFrame:\")\n",
    "print(df)\n",
    "print(\"\\nData Types:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the `Birthdate` to string format (using `astype`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Birthdate'] = df['Birthdate'].astype(str)\n",
    "print(\"\\nConverted Birthdate to string:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert `Name` to `category` data type (for efficiency):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Name'] = df['Name'].astype('category')\n",
    "print(\"\\nConverted Name to category:\")\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Step 3: Filter and Operate on Data Based on Data Types\n",
    "\n",
    "Now that we have the data types set, let’s filter and perform operations on the columns based on their types.\n",
    "\n",
    "#### 1. Filter rows where `Age` is greater than or equal to 30:\n",
    "\n",
    "```python\n",
    "adults = df[df['Age'] >= 30]\n",
    "print(\"\\nPeople aged 30 or older:\")\n",
    "print(adults)\n",
    "```\n",
    "\n",
    "#### 2. Filter rows where `Is_Adult` is `True`:\n",
    "\n",
    "```python\n",
    "adults_only = df[df['Is_Adult'] == 1]\n",
    "print(\"\\nOnly adults (Is_Adult=True):\")\n",
    "print(adults_only)\n",
    "```\n",
    "\n",
    "#### 3. Filter out rows where `Height` is greater than or equal to 6.0:\n",
    "\n",
    "```python\n",
    "tall_people = df[df['Height'] >= 6.0]\n",
    "print(\"\\nPeople with Height >= 6.0:\")\n",
    "print(tall_people)\n",
    "```\n",
    "\n",
    "#### 4. Extract birth year from the `Birthdate` column:\n",
    "\n",
    "```python\n",
    "df['Birthyear'] = df['Birthdate'].apply(lambda x: x.split('-')[0])\n",
    "print(\"\\nExtracted Birthyear:\")\n",
    "print(df[['Name', 'Birthyear']])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Null Value Functions `.isnull()`, `.dropna()`, and `.fillna()`\n",
    "\n",
    "Let's create a **DataFrame** with some **null (NaN) values** \n",
    "\n",
    "### Step 1: Create DataFrame with Null Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a DataFrame with NaN values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', None, 'Eva'],\n",
    "    'Age': [25, None, 35, 40, None],\n",
    "    'Height': [5.5, 6.2, None, 5.9, 5.6],\n",
    "    'City': ['New York', None, 'San Francisco', 'Boston', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame with Null Values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values\n",
    "null_check = df.isnull()\n",
    "print(\"\\nCheck for Null Values:\")\n",
    "print(null_check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Step 2: Check for Null Values with `.isnull()`\n",
    "\n",
    "The `.isnull()` function returns a DataFrame of the same shape as the original DataFrame, but with `True` for missing values and `False` for non-missing values.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Drop Rows with Null Values using `.dropna()`\n",
    "\n",
    "We can remove any rows that contain **NaN** values using `.dropna()`. This can be done either row-wise (by default) or column-wise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with any NaN values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nDataFrame After Dropping Rows with Null Values:\")\n",
    "print(df_dropped)\n",
    "\n",
    "# Drop rows where all values are NaN\n",
    "df_dropped_all = df.dropna(how='all')\n",
    "print(\"\\nDataFrame After Dropping Rows with All Null Values:\")\n",
    "print(df_dropped_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fill Null Values with `.fillna()`\n",
    "\n",
    "You can fill **NaN** values with a specific value using `.fillna()`. For example, let's fill all the **NaN** values with `0` and with column-specific values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with a constant value (e.g., 0)\n",
    "df_filled_zero = df.fillna(0)\n",
    "print(\"\\nDataFrame After Filling Null Values with 0:\")\n",
    "print(df_filled_zero)\n",
    "\n",
    "# Fill NaN values with different values per column\n",
    "df_filled_custom = df.fillna({'Age': 30, 'Height': 5.5, 'City': 'Unknown'})\n",
    "print(\"\\nDataFrame After Filling Null Values with Custom Values:\")\n",
    "print(df_filled_custom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Step 5: Forward Fill and Backward Fill using `.ffill()` and `.bfill()`\n",
    "\n",
    "You can also fill **NaN** values by propagating the previous or next valid value in the column using **forward fill** (`.ffill()`) and **backward fill** (`.bfill()`).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward fill (propagate previous value)\n",
    "df_ffilled = df.ffill()\n",
    "print(\"\\nDataFrame After Forward Fill:\")\n",
    "print(df_ffilled)\n",
    "\n",
    "# Backward fill (propagate next value)\n",
    "df_bfilled = df.bfill()\n",
    "print(\"\\nDataFrame After Backward Fill:\")\n",
    "print(df_bfilled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Full Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create DataFrame with NaN values\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', None, 'Eva'],\n",
    "    'Age': [25, None, 35, 40, None],\n",
    "    'Height': [5.5, 6.2, None, 5.9, 5.6],\n",
    "    'City': ['New York', None, 'San Francisco', 'Boston', 'Chicago']\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame with Null Values:\")\n",
    "print(df)\n",
    "\n",
    "# Check for null values\n",
    "null_check = df.isnull()\n",
    "print(\"\\nCheck for Null Values:\")\n",
    "print(null_check)\n",
    "\n",
    "# Drop rows with any NaN values\n",
    "df_dropped = df.dropna()\n",
    "print(\"\\nDataFrame After Dropping Rows with Null Values:\")\n",
    "print(df_dropped)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows where all values are NaN\n",
    "df_dropped_all = df.dropna(how='all')\n",
    "print(\"\\nDataFrame After Dropping Rows with All Null Values:\")\n",
    "print(df_dropped_all)\n",
    "\n",
    "# Fill NaN values with a constant value (e.g., 0)\n",
    "df_filled_zero = df.fillna(0)\n",
    "print(\"\\nDataFrame After Filling Null Values with 0:\")\n",
    "print(df_filled_zero)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with different values per column\n",
    "df_filled_custom = df.fillna({'Age': 30, 'Height': 5.5, 'City': 'Unknown'})\n",
    "print(\"\\nDataFrame After Filling Null Values with Custom Values:\")\n",
    "print(df_filled_custom)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Original DataFrame with Null Values:\")\n",
    "print(df)\n",
    "\n",
    "# Forward fill (propagate previous value)\n",
    "df_ffilled = df.ffill()\n",
    "print(\"\\nDataFrame After Forward Fill:\")\n",
    "print(df_ffilled)\n",
    "\n",
    "# Backward fill (propagate next value)\n",
    "df_bfilled = df.bfill()\n",
    "print(\"\\nDataFrame After Backward Fill:\")\n",
    "print(df_bfilled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Slicing: Accessing Subsets of Data\n",
    "\n",
    "Pandas slicing allows you to efficiently access specific subsets of data from a **Series** or **DataFrame** using various methods. Here’s a detailed guide on **slicing** in Pandas.\n",
    "\n",
    "### 1. **Slicing in Pandas Series**\n",
    "\n",
    "A **Series** is a one-dimensional array, and you can slice it using the same syntax as Python lists (i.e., `start:stop:step`).\n",
    "\n",
    "#### 1.1. **Basic Indexing and Slicing**\n",
    "\n",
    "- **Accessing a single element**: Use integer indexing to get a specific element.\n",
    "- **Slicing a portion of a Series**: Use the same slice notation `start:stop:step`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a Series\n",
    "s = pd.Series([10, 20, 30, 40, 50, 60])\n",
    "\n",
    "# Accessing a single element (index 2)\n",
    "print(s[2])  # Output: 30\n",
    "\n",
    "# Slicing a portion of the Series (from index 1 to 4, excluding index 4)\n",
    "print(s[1:4])  # Output: 1    20\n",
    "               #         2    30\n",
    "               #         3    40\n",
    "\n",
    "# Slicing with a step (every 2nd element)\n",
    "print(s[::2])  # Output: 0    10\n",
    "               #         2    30\n",
    "               #         4    50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2. **Using Negative Indices**\n",
    "\n",
    "You can also use negative indices to access elements from the end of the Series.\n",
    "\n",
    "```python\n",
    "# Accessing the last element\n",
    "print(s[-1])  # Output: 60\n",
    "\n",
    "# Slicing from the second-to-last element to the beginning\n",
    "print(s[-2:])  # Output: 4    50\n",
    "               #         5    60\n",
    "```\n",
    "\n",
    "#### 1.3. **Slicing with Conditions**\n",
    "\n",
    "You can apply conditions while slicing Series.\n",
    "\n",
    "```python\n",
    "# Select elements greater than 30\n",
    "print(s[s > 30])  # Output: 3    40\n",
    "                  #         4    50\n",
    "                  #         5    60\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Slicing in Pandas DataFrame**\n",
    "\n",
    "A **DataFrame** is a two-dimensional table (rows and columns), and you can slice data by accessing specific rows, columns, or both.\n",
    "\n",
    "#### 2.1. **Selecting Columns**\n",
    "\n",
    "You can select columns by their name (as a string) or by passing a list of column names.\n",
    "\n",
    "```python\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [5, 6, 7, 8],\n",
    "    'C': [9, 10, 11, 12]\n",
    "})\n",
    "\n",
    "# Selecting a single column\n",
    "print(df['A'])  # Output: 0    1\n",
    "                #         1    2\n",
    "                #         2    3\n",
    "                #         3    4\n",
    "\n",
    "# Selecting multiple columns\n",
    "print(df[['A', 'C']])  # Output:   A   C\n",
    "                       #         0  1   9\n",
    "                       #         1  2  10\n",
    "                       #         2  3  11\n",
    "                       #         3  4  12\n",
    "```\n",
    "\n",
    "#### 2.2. **Selecting Rows by Index Position**\n",
    "\n",
    "You can slice rows using the `.iloc[]` method, which uses **integer-based indexing** (similar to Python’s list slicing).\n",
    "\n",
    "```python\n",
    "# Select rows from index 1 to 3 (exclusive)\n",
    "print(df.iloc[1:4])  # Output:    A  B   C\n",
    "                    #         1  2  6  10\n",
    "                    #         2  3  7  11\n",
    "                    #         3  4  8  12\n",
    "```\n",
    "\n",
    "#### 2.3. **Selecting Rows by Label**\n",
    "\n",
    "You can also slice rows by their label index using the `.loc[]` method, which uses **label-based indexing** (inclusive of the end index).\n",
    "\n",
    "```python\n",
    "# Create DataFrame with custom indices\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3, 4],\n",
    "    'B': [5, 6, 7, 8],\n",
    "    'C': [9, 10, 11, 12]\n",
    "}, index=['row1', 'row2', 'row3', 'row4'])\n",
    "\n",
    "# Select rows by label\n",
    "print(df.loc['row1':'row3'])  # Output:       A  B   C\n",
    "                              #         row1  1  5   9\n",
    "                              #         row2  2  6  10\n",
    "                              #         row3  3  7  11\n",
    "```\n",
    "\n",
    "#### 2.4. **Selecting Rows and Columns Together**\n",
    "\n",
    "You can combine row and column slicing by specifying both row and column indexes.\n",
    "\n",
    "```python\n",
    "# Select rows from 1 to 3 and columns 'A' and 'C'\n",
    "print(df.loc[1:3, ['A', 'C']])  # Output:    A   C\n",
    "                                #         row2  2  10\n",
    "                                #         row3  3  11\n",
    "                                #         row4  4  12\n",
    "```\n",
    "\n",
    "#### 2.5. **Slicing DataFrame Using Conditions**\n",
    "\n",
    "Just like Series, you can slice DataFrame rows based on conditions.\n",
    "\n",
    "```python\n",
    "# Select rows where column 'A' is greater than 2\n",
    "print(df[df['A'] > 2])  # Output:       A  B   C\n",
    "                       #         row3  3  7  11\n",
    "                       #         row4  4  8  12\n",
    "```\n",
    "\n",
    "#### 2.6. **Using `.iloc[]` for Both Rows and Columns by Position**\n",
    "\n",
    "The `.iloc[]` method allows you to slice rows and columns based on **integer position** rather than labels.\n",
    "\n",
    "```python\n",
    "# Select rows 1 to 2 and columns 0 to 1 (indexing is zero-based)\n",
    "print(df.iloc[1:3, 0:2])  # Output:    A  B\n",
    "                          #         row2  2  6\n",
    "                          #         row3  3  7\n",
    "```\n",
    "\n",
    "#### 2.7. **Using `.loc[]` for Both Rows and Columns by Label**\n",
    "\n",
    "The `.loc[]` method is label-based, and it allows you to slice rows and columns by their label names.\n",
    "\n",
    "```python\n",
    "# Select rows 'row2' to 'row3' and columns 'A' and 'C'\n",
    "print(df.loc['row2':'row3', ['A', 'C']])  # Output:     A   C\n",
    "                                         #         row2  2  10\n",
    "                                         #         row3  3  11\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### Summary of Pandas Slicing\n",
    "\n",
    "| Operation                         | Series Example                     | DataFrame Example                       |\n",
    "|------------------------------------|-------------------------------------|-----------------------------------------|\n",
    "| **Single Element Access**          | `s[2]`                              | `df['A'][2]`                            |\n",
    "| **Slicing a Range**                | `s[1:4]`                            | `df.iloc[1:4]`                          |\n",
    "| **Negative Indexing**              | `s[-1]`                             | `df.iloc[-1]`                           |\n",
    "| **Conditional Slicing**            | `s[s > 30]`                         | `df[df['A'] > 2]`                       |\n",
    "| **Selecting Columns**              | `df['A']`                           | `df[['A', 'B']]`                        |\n",
    "| **Row Selection by Label**         | `df.loc[1:3]`                       | `df.loc['row1':'row3']`                 |\n",
    "| **Row and Column Selection**       | `df.iloc[1:3, 0:2]`                 | `df.loc['row1':'row3', ['A', 'C']]`     |\n",
    "| **Column Selection by Condition**  | N/A                                 | `df[df['A'] > 2]`                       |\n",
    "\n",
    "---\n",
    "\n",
    "### Practice Exercise\n",
    "\n",
    "1. Create a DataFrame with some missing data (e.g., `NaN`).\n",
    "2. Slice rows based on a condition (e.g., select rows where `Age` > 30).\n",
    "3. Try different slicing techniques like `.iloc[]` and `.loc[]` to select specific rows and columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding and Removing records in Pandas\n",
    "\n",
    "### 1. **Adding Data to a DataFrame**\n",
    "\n",
    "#### 1.1 **Adding a Row (Append)**\n",
    "\n",
    "You can add a row to a DataFrame using the `.loc[]` or `.append()` method. However, note that `.append()` is being deprecated in future versions, and it's recommended to use `pd.concat()` instead.\n",
    "\n",
    "##### Method 1: Using `.loc[]` to Add a Row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Name': ['Alice', 'Bob', 'Charlie'],\n",
    "    'Age': [25, 30, 35],\n",
    "    'City': ['New York', 'Los Angeles', 'Chicago']\n",
    "})\n",
    "\n",
    "# Adding a new row using loc (by index label)\n",
    "df.loc[3] = ['David', 40, 'San Francisco']\n",
    "print(\"DataFrame after adding a new row:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 2: Using `pd.concat()` (Recommended)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new row using pd.concat\n",
    "new_row = pd.DataFrame({'Name': ['Eva'], 'Age': [28], 'City': ['Miami']})\n",
    "df = pd.concat([df, new_row], ignore_index=True)\n",
    "print(\"\\nDataFrame after using concat:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.2 **Adding a Column**\n",
    "\n",
    "You can add a new column by directly assigning values to it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a new column\n",
    "df['Occupation'] = ['Engineer', 'Doctor', 'Artist', 'Nurse', 'Scientist']\n",
    "print(\"\\nDataFrame after adding a new column:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 1.3 **Adding Multiple Columns**\n",
    "\n",
    "You can also add multiple columns at once using `pd.DataFrame` or `assign()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding multiple columns\n",
    "df[['Salary', 'Country']] = pd.DataFrame([[50000, 'USA'], [60000, 'USA'], [70000, 'USA'], [45000, 'USA'], [80000, 'USA']])\n",
    "print(\"\\nDataFrame after adding multiple columns:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "### 2. **Removing Data from a DataFrame**\n",
    "\n",
    "#### 2.1 **Removing a Row**\n",
    "\n",
    "To remove rows, you can use the `.drop()` method. You can drop rows by **index** or using a **condition**.\n",
    "\n",
    "##### Method 1: Drop by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping a row by index\n",
    "df = df.drop(1)  # Drop row with index 1 (Bob)\n",
    "print(\"\\nDataFrame after dropping a row by index:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Method 2: Drop Multiple Rows by Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping multiple rows by index\n",
    "df = df.drop([0, 2])  # Drop rows with index 0 (Alice) and 2 (Charlie)\n",
    "print(\"\\nDataFrame after dropping multiple rows by index:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "##### Method 3: Drop Rows by Condition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows based on a condition (e.g., Age > 30)\n",
    "df = df[df['Age'] <= 30]\n",
    "print(\"\\nDataFrame after dropping rows where Age > 30:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.2 **Removing a Column**\n",
    "\n",
    "You can remove columns using the `.drop()` method by specifying the `axis=1` argument.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping a column by name\n",
    "df = df.drop('Occupation', axis=1)\n",
    "print(\"\\nDataFrame after dropping a column:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.3 **Removing Columns by Condition**\n",
    "\n",
    "You can drop columns based on certain conditions or values, but this requires checking the condition first and then using `.drop()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop a column if its values are all NaN\n",
    "df = df.dropna(axis=1, how='all')\n",
    "print(\"\\nDataFrame after dropping columns where all values are NaN:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "#### 2.4 **Removing Rows with Missing Data (NaN)**\n",
    "\n",
    "You can remove rows containing **NaN** values using `.dropna()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping rows with any NaN values\n",
    "df = df.dropna()\n",
    "print(\"\\nDataFrame after dropping rows with NaN values:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.5 **Removing Duplicates**\n",
    "\n",
    "You can remove duplicate rows using `.drop_duplicates()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding some duplicate rows\n",
    "df = df.append(df.iloc[0])  # Adding a duplicate row\n",
    "print(\"\\nDataFrame with duplicate rows:\")\n",
    "print(df)\n",
    "\n",
    "# Dropping duplicate rows\n",
    "df = df.drop_duplicates()\n",
    "print(\"\\nDataFrame after dropping duplicates:\")\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping\n",
    "\n",
    "Grouping is a powerful feature in **Pandas** that allows you to **split** the data into groups, **apply** a function (like aggregation or transformation), and **combine** the results back into a DataFrame. This is commonly used for **summarizing** data, such as computing averages, sums, counts, etc., for different categories or groups.\n",
    "\n",
    "The basic steps for grouping are:\n",
    "\n",
    "1. **Split**: Split the data based on some criteria (e.g., a column).\n",
    "2. **Apply**: Perform an operation on each group.\n",
    "3. **Combine**: Combine the results back into a DataFrame.\n",
    "\n",
    "We use the `.groupby()` method for grouping in Pandas.\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Basic Grouping**\n",
    "\n",
    "Let's create a simple dataset and perform basic grouping.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a sample DataFrame\n",
    "data = {\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eva', 'Frank', 'Grace', 'Hannah', 'Ian', 'Jack'],\n",
    "    'Department': ['HR', 'IT', 'IT', 'HR', 'Finance', 'Finance', 'IT', 'HR', 'Finance', 'IT'],\n",
    "    'Salary': [50000, 70000, 80000, 60000, 90000, 95000, 85000, 55000, 75000, 73000],\n",
    "    'Experience': [5, 7, 8, 6, 10, 12, 9, 4, 15, 11]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "print(\"Original DataFrame:\")\n",
    "print(df)\n",
    "```\n",
    "\n",
    "#### Output:\n",
    "```\n",
    "      Name Department  Salary  Experience\n",
    "0    Alice         HR   50000           5\n",
    "1      Bob         IT   70000           7\n",
    "2  Charlie         IT   80000           8\n",
    "3    David         HR   60000           6\n",
    "4      Eva    Finance   90000          10\n",
    "5    Frank    Finance   95000          12\n",
    "6    Grace         IT   85000           9\n",
    "7   Hannah         HR   55000           4\n",
    "8      Ian    Finance   75000          15\n",
    "9     Jack         IT   73000          11\n",
    "```\n",
    "\n",
    "### 2. **Grouping by a Single Column**\n",
    "\n",
    "To group the data by **Department** and compute the **average salary** for each department, we can use the `.groupby()` method followed by `.agg()` or an aggregation function like `.mean()`.\n",
    "\n",
    "```python\n",
    "# Group by 'Department' and calculate the average 'Salary'\n",
    "grouped = df.groupby('Department')['Salary'].mean()\n",
    "\n",
    "print(\"\\nAverage Salary per Department:\")\n",
    "print(grouped)\n",
    "```\n",
    "\n",
    "#### Output:\n",
    "```\n",
    "Department\n",
    "Finance    82500.0\n",
    "HR         57500.0\n",
    "IT         75400.0\n",
    "Name: Salary, dtype: float64\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- `df.groupby('Department')`: This splits the DataFrame into groups based on the values in the `Department` column.\n",
    "- `['Salary']`: This selects the `Salary` column for aggregation.\n",
    "- `.mean()`: This calculates the mean salary for each group.\n",
    "\n",
    "---\n",
    "\n",
    "### 3. **Grouping and Aggregating Multiple Columns**\n",
    "\n",
    "You can also apply different aggregation functions to multiple columns at once. For example, to calculate both the **average salary** and the **sum of experience** for each department:\n",
    "\n",
    "```python\n",
    "# Group by 'Department' and calculate the mean salary and sum of experience\n",
    "grouped_multi = df.groupby('Department').agg({\n",
    "    'Salary': 'mean',       # Calculate mean salary\n",
    "    'Experience': 'sum'     # Calculate sum of experience\n",
    "})\n",
    "\n",
    "print(\"\\nMean Salary and Sum of Experience per Department:\")\n",
    "print(grouped_multi)\n",
    "```\n",
    "\n",
    "#### Output:\n",
    "```\n",
    "            Salary  Experience\n",
    "Department                     \n",
    "Finance    82500.0         37\n",
    "HR         57500.0         15\n",
    "IT         75400.0         35\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- `.agg()` allows you to specify different aggregation functions for each column. In this case:\n",
    "  - `'Salary': 'mean'`: Calculates the mean salary.\n",
    "  - `'Experience': 'sum'`: Calculates the sum of experience.\n",
    "\n",
    "---\n",
    "\n",
    "### 4. **Grouping by Multiple Columns**\n",
    "\n",
    "You can also group by more than one column. For example, to group by both **Department** and **Experience**:\n",
    "\n",
    "```python\n",
    "# Group by 'Department' and 'Experience' and calculate the average salary\n",
    "grouped_multi_columns = df.groupby(['Department', 'Experience'])['Salary'].mean()\n",
    "\n",
    "print(\"\\nAverage Salary by Department and Experience:\")\n",
    "print(grouped_multi_columns)\n",
    "```\n",
    "\n",
    "#### Output:\n",
    "```\n",
    "Department  Experience\n",
    "Finance     10            90000.0\n",
    "            12            95000.0\n",
    "            15            75000.0\n",
    "HR           4            55000.0\n",
    "            5            50000.0\n",
    "            6            60000.0\n",
    "IT           7            70000.0\n",
    "            8            80000.0\n",
    "            9            85000.0\n",
    "            11           73000.0\n",
    "Name: Salary, dtype: float64\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- `groupby(['Department', 'Experience'])`: Groups by both `Department` and `Experience` columns.\n",
    "- The result is a **MultiIndex**, with the first level being the department and the second level being the experience.\n",
    "\n",
    "---\n",
    "\n",
    "### 5. **Using `size()` to Count the Number of Records in Each Group**\n",
    "\n",
    "To get the count of records in each group, you can use `.size()` instead of an aggregation function like `mean()`.\n",
    "\n",
    "```python\n",
    "# Group by 'Department' and count the number of records in each department\n",
    "count_groups = df.groupby('Department').size()\n",
    "\n",
    "print(\"\\nNumber of records per Department:\")\n",
    "print(count_groups)\n",
    "```\n",
    "\n",
    "#### Output:\n",
    "```\n",
    "Department\n",
    "Finance    3\n",
    "HR         3\n",
    "IT         4\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "**Explanation**:\n",
    "- `.size()` counts the number of records in each group.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `apply()` and `applymap()` in Pandas\n",
    "Pandas provides `apply()` and `applymap()` to apply functions to DataFrames and Series. These are useful for performing row-wise, column-wise, or element-wise operations on your data.\n",
    "\n",
    "---\n",
    "\n",
    "### **1. `apply()`**\n",
    "The `apply()` function is used to apply a function along an **axis** (rows or columns) of a DataFrame or on elements of a Series.\n",
    "\n",
    "#### Key Points:\n",
    "- Works on both **Series** and **DataFrames**.\n",
    "- Can apply the function row-wise (`axis=1`) or column-wise (`axis=0`) for DataFrames.\n",
    "- Accepts a `lambda` or a custom function.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 1: Applying on a Series\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "# Sample Series\n",
    "s = pd.Series([1, 2, 3, 4, 5])\n",
    "\n",
    "# Apply a lambda function to square each element\n",
    "result = s.apply(lambda x: x**2)\n",
    "print(result)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "0     1\n",
    "1     4\n",
    "2     9\n",
    "3    16\n",
    "4    25\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Applying on a DataFrame\n",
    "```python\n",
    "# Sample DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'A': [1, 2, 3],\n",
    "    'B': [4, 5, 6],\n",
    "    'C': [7, 8, 9]\n",
    "})\n",
    "\n",
    "# Apply a lambda function column-wise (default is axis=0)\n",
    "column_sum = df.apply(lambda col: col.sum(), axis=0)\n",
    "print(\"Column-wise sum:\")\n",
    "print(column_sum)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Column-wise sum:\n",
    "A     6\n",
    "B    15\n",
    "C    24\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 3: Row-wise Operations\n",
    "```python\n",
    "# Apply a lambda function row-wise\n",
    "row_sum = df.apply(lambda row: row.sum(), axis=1)\n",
    "print(\"\\nRow-wise sum:\")\n",
    "print(row_sum)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Row-wise sum:\n",
    "0    12\n",
    "1    15\n",
    "2    18\n",
    "dtype: int64\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. `applymap()`**\n",
    "The `applymap()` function is used to apply a function **element-wise** on a DataFrame. Unlike `apply()`, it works on individual elements of a DataFrame, not rows or columns.\n",
    "\n",
    "#### Key Points:\n",
    "- Works **only on DataFrames** (not Series).\n",
    "- Applies the function to each individual element of the DataFrame.\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 1: Element-wise Transformation\n",
    "```python\n",
    "# Apply a lambda function to square each element in the DataFrame\n",
    "squared_df = df.applymap(lambda x: x**2)\n",
    "print(\"\\nSquared DataFrame:\")\n",
    "print(squared_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Squared DataFrame:\n",
    "    A   B   C\n",
    "0   1  16  49\n",
    "1   4  25  64\n",
    "2   9  36  81\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Example 2: Formatting Data\n",
    "You can use `applymap()` for tasks like formatting strings or modifying individual elements.\n",
    "\n",
    "```python\n",
    "# Example: Add a string prefix to all elements\n",
    "formatted_df = df.applymap(lambda x: f\"Value-{x}\")\n",
    "print(\"\\nFormatted DataFrame:\")\n",
    "print(formatted_df)\n",
    "```\n",
    "\n",
    "**Output:**\n",
    "```\n",
    "Formatted DataFrame:\n",
    "           A         B         C\n",
    "0  Value-1  Value-4  Value-7\n",
    "1  Value-2  Value-5  Value-8\n",
    "2  Value-3  Value-6  Value-9\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **When to Use `apply()` vs `applymap()`**\n",
    "| Feature                | `apply()`                               | `applymap()`                           |\n",
    "|------------------------|------------------------------------------|----------------------------------------|\n",
    "| **Input**              | Series or DataFrame                     | Only DataFrame                        |\n",
    "| **Output**             | Series or DataFrame                     | DataFrame                              |\n",
    "| **Function Application** | Applies to rows/columns or individual elements | Applies only to individual elements    |\n",
    "| **Example Use**        | Aggregating rows/columns, row-wise operations | Element-wise transformations          |\n",
    "\n",
    "---\n",
    "\n",
    "### Combined Example: `apply()` and `applymap()` with `lambda`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "data = {\n",
    "    \"Product\": [\"Apple\", \"Banana\", \"Carrot\"],\n",
    "    \"Price\": [100, 30, 50],\n",
    "    \"Quantity\": [3, 10, 5]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# 1. Apply column-wise: Calculate total cost\n",
    "df[\"Total_Cost\"] = df.apply(lambda row: row[\"Price\"] * row[\"Quantity\"], axis=1)\n",
    "print(\"DataFrame with Total Cost:\\n\", df)\n",
    "\n",
    "# 2. Applymap element-wise: Format prices with a currency symbol\n",
    "formatted_df = df.applymap(lambda x: f\"₹{x}\" if isinstance(x, int) else x)\n",
    "print(\"\\nFormatted DataFrame:\\n\", formatted_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
